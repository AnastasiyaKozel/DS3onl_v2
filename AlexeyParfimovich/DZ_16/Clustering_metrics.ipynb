{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering metrics - alternatives to the _elbow method_\n",
    "### Dr. Tirthajyoti Sarkar, Fremont, CA 94536\n",
    "\n",
    "Кластеризация — важная часть конвейера машинного обучения для бизнеса или научных предприятий, использующих науку о данных. Как следует из названия, это помогает идентифицировать группы тесно связанных (по некоторой мере расстояния) точек данных в блоке данных, которые в противном случае было бы трудно понять.\n",
    "\n",
    "Популярный метод, такой как кластеризация k-средних, кажется, не дает полностью удовлетворительного ответа, когда мы задаем основной вопрос:\n",
    "> **\"Как нам узнать фактическое количество кластеров для начала?\"**\n",
    "\n",
    "Этот вопрос является критически важным, поскольку процесс кластеризации часто предшествует дальнейшей обработке данных отдельных кластеров, и поэтому объем вычислительных ресурсов может зависеть от этого измерения.\n",
    "\n",
    "В случае с бизнес-аналитикой последствия могут быть хуже. Для такой аналитики часто делается кластеризация с целью сегментации рынка. Поэтому легко предположить, что в зависимости от количества кластеров для решения проблемы будет выделен соответствующий маркетинговый персонал. Следовательно, неправильная оценка количества кластеров может привести к неоптимальному распределению ценных ресурсов.\n",
    "\n",
    "Для метода кластеризации k-средних наиболее распространенным подходом к ответу на этот вопрос является так называемый метод локтя. Он включает в себя запуск алгоритма несколько раз в цикле с увеличением числа вариантов выбора кластера, а затем построение оценки кластеризации в зависимости от количества кластеров.\n",
    "\n",
    "В этой записной книжке мы показываем, какую метрику использовать для визуализации и определения оптимального количества кластеров намного лучше, чем обычный метод «локтя».\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create synthetic data using Scikit learn `make_blob` method\n",
    "\n",
    "- Number of features: 4\n",
    "- Number of clusters: 5\n",
    "- Number of samples: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 4\n",
    "n_cluster = 5\n",
    "cluster_std = 1.2\n",
    "n_samples = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = make_blobs(n_samples=n_samples,n_features=n_features,centers=n_cluster,cluster_std=cluster_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = data1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(data=d1,columns=['Feature_'+str(i) for i in range(1,n_features+1)])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_vars=list(combinations(df1.columns,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lst_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "for i in range(1,7):\n",
    "    plt.subplot(2,3,i)\n",
    "    dim1=lst_vars[i-1][0]\n",
    "    dim2=lst_vars[i-1][1]\n",
    "    plt.scatter(df1[dim1],df1[dim2],c=data1[1],edgecolor='k',s=150)\n",
    "    plt.xlabel(f\"{dim1}\",fontsize=13)\n",
    "    plt.ylabel(f\"{dim2}\",fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How are the classes separated (boxplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,14))\n",
    "for i,c in enumerate(df1.columns):\n",
    "    plt.subplot(3,2,i+1)\n",
    "    sns.boxplot(y=df1[c],x=data1[1])\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.xlabel(\"Class\",fontsize=15)\n",
    "    plt.ylabel(c,fontsize=15)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unlabled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score,v_measure_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running k-means and computing inter-cluster distance score for various *k* values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_inertia = []\n",
    "ks = range(1,11)\n",
    "\n",
    "for k in ks:\n",
    "    clf_kmeans = KMeans(n_clusters=k)\n",
    "    clusters_kmeans = clf_kmeans.fit_predict(X_scaled, )\n",
    "    k_inertia.append(clf_kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_scores= []\n",
    "km_silhouette = []\n",
    "vmeasure_score =[]\n",
    "db_score = []\n",
    "k_inertia = []\n",
    "for i in range(2,12):\n",
    "    km = KMeans(n_clusters=i, random_state=0).fit(X_scaled)\n",
    "    preds = km.predict(X_scaled)\n",
    "\n",
    "    k_inertia.append(km.inertia_)\n",
    "    \n",
    "    print(\"Score for number of cluster(s) {}: {}\".format(i,km.score(X_scaled)))\n",
    "    km_scores.append(-km.score(X_scaled))\n",
    "    \n",
    "    silhouette = silhouette_score(X_scaled,preds)\n",
    "    km_silhouette.append(silhouette)\n",
    "    print(\"Silhouette score for number of cluster(s) {}: {}\".format(i,silhouette))\n",
    "    \n",
    "    db = davies_bouldin_score(X_scaled,preds)\n",
    "    db_score.append(db)\n",
    "    print(\"Davies Bouldin score for number of cluster(s) {}: {}\".format(i,db))\n",
    "    \n",
    "    v_measure = v_measure_score(y,preds)\n",
    "    vmeasure_score.append(v_measure)\n",
    "    print(\"V-measure score for number of cluster(s) {}: {}\".format(i,v_measure))\n",
    "    print(\"-\"*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The elbow method for determining number of k_inertia\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,12)],y=k_inertia,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"K-means score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,12)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The elbow method for determining number of clusters\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,12)],y=km_scores,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"K-means score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,12)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=[i for i in range(2,12)],y=vmeasure_score,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"V-measure score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The silhouette coefficient method \\nfor determining number of clusters\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,12)],y=km_silhouette,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"Silhouette score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,12)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=[i for i in range(2,12)],y=db_score,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Davies-Bouldin score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation-maximization (Gaussian Mixture Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_bic= []\n",
    "gm_score=[]\n",
    "for i in range(2,12):\n",
    "    gm = GaussianMixture(n_components=i,n_init=10,tol=1e-3,max_iter=1000).fit(X_scaled)\n",
    "    print(\"BIC for number of cluster(s) {}: {}\".format(i,gm.bic(X_scaled)))\n",
    "    print(\"Log-likelihood score for number of cluster(s) {}: {}\".format(i,gm.score(X_scaled)))\n",
    "    print(\"-\"*100)\n",
    "    gm_bic.append(-gm.bic(X_scaled))\n",
    "    gm_score.append(gm.score(X_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The Gaussian Mixture model BIC \\nfor determining number of clusters\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,12)],y=np.log(gm_bic),s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"Log of Gaussian mixture BIC score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,12)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=[i for i in range(2,12)],y=gm_score,s=150,edgecolor='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "N_FEATURES=8\n",
    "N_CLASSES=10\n",
    "X,Y=make_blobs(n_samples=2000, \n",
    "                      n_features=N_FEATURES, \n",
    "                      centers=np.random.uniform(0,9,size=(N_CLASSES,N_FEATURES)), \n",
    "                      random_state=42, )\n",
    "TOTAL_SAMPLES=X.shape[0]\n",
    "import matplotlib.pyplot as pp\n",
    "pp.scatter(X[:,0],X[:,2],c=Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(random_state=42)\n",
    "# используем метод fit_transform вместо fit, т.к. класс TSNE не использует метод transform\n",
    "X_tsne = tsne.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_SAMPLES=X.shape[0]\n",
    "import matplotlib.pyplot as pp\n",
    "pp.scatter(X_tsne[:,0],X_tsne[:,1],c=Y);\n",
    "plt.xlabel(\"t-SNE признак 0\")\n",
    "plt.xlabel(\"t-SNE признак 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_scores= []\n",
    "km_silhouette = []\n",
    "vmeasure_score =[]\n",
    "db_score = []\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score,v_measure_score\n",
    "#X_scaled=scaler.fit_transform(X)\n",
    "X_scaled = X\n",
    "for i in range(2,15):\n",
    "    km = KMeans(n_clusters=i, random_state=0).fit(X_scaled)\n",
    "    preds = km.predict(X_scaled)\n",
    "    \n",
    "    print(\"Score for number of cluster(s) {}: {}\".format(i,km.score(X_scaled)))\n",
    "    km_scores.append(-km.score(X_scaled))\n",
    "    \n",
    "    silhouette = silhouette_score(X_scaled,preds)\n",
    "    km_silhouette.append(silhouette)\n",
    "    print(\"Silhouette score for number of cluster(s) {}: {}\".format(i,silhouette))\n",
    "    \n",
    "    db = davies_bouldin_score(X_scaled,preds)\n",
    "    db_score.append(db)\n",
    "    print(\"Davies Bouldin score for number of cluster(s) {}: {}\".format(i,db))\n",
    "    \n",
    "    v_measure = v_measure_score(Y,preds)\n",
    "    vmeasure_score.append(v_measure)\n",
    "    print(\"V-measure score for number of cluster(s) {}: {}\".format(i,v_measure))\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The elbow method for determining number of clusters\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,15)],y=km_scores,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"K-means score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,15)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=[i for i in range(2,15)],y=vmeasure_score,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"V-measure score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The silhouette coefficient method \\nfor determining number of clusters\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,15)],y=km_silhouette,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"Silhouette score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,15)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=[i for i in range(2,15)],y=db_score,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Davies-Bouldin score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " \n",
    "from math import nan\n",
    "\n",
    "\n",
    "TRAIN_CSV_PATH = 'titanic_train.csv'\n",
    "TEST_CSV_PATH = 'titanic_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df:pd.DataFrame):\n",
    " \n",
    "    # Для признака \"Cabin\" - часть пропущенных значений заменить совпадающими по номеру билета (по одному билету может быть зарегистрирована группа пассажиров)\n",
    "    df['Cabin'] = df.groupby(['Ticket'])['Cabin'].transform(lambda x: x.fillna(x.mode()[0] if x.count()>0 else nan))\n",
    "\n",
    "    # Выделить из признака \"Cabin\"(номер каюты) палубу \"Deck\"\n",
    "    df.insert(10,'Deck', df['Cabin'].str.extract(r'(\\D+)', expand = True)[0])\n",
    "    # Исключить из признака ошибочные буквы, например \"f e\"  или \"f g\" - при этом использовать последнюю букву \n",
    "    df['Deck'] = df['Deck'].str[-1:]\n",
    "\n",
    "    # Выделить из признака Name новый признак Title(титул-приставка к имени пассажира)\n",
    "    df.insert(2,'Title', df['Name'].str.extract(r' (\\w+)\\.', expand = True)[0] )\n",
    "    df.loc[df['Title'].isin(['capt','col','major']), 'Title'] = 'military'\n",
    "    df.loc[df['Title'].isin(['lady','donа','countess']), 'Title'] = 'lady'\n",
    "    df.loc[df['Title'].isin(['sir','don','jonkheer']), 'Title'] = 'sir'\n",
    "    df.loc[df['Title'].isin(['ms','mlle']), 'Title'] = 'miss'\n",
    "    df.loc[df['Title'].isin(['mme']), 'Title'] = 'mrs'\n",
    "\n",
    "    # Для признака \"Age\" - заменить пропущенные значения медианным значением группы по признаку 'Title'(титул)\n",
    "    df['Age'] = df.groupby(['Title'])['Age'].transform(lambda x: x.fillna(x.median() if x.count()>0 else nan))\n",
    "    # ВЫделить признак возрастной категории - до 1 года, до 10 лет, и т.д.\n",
    "    df.insert(6,'Age_category', df['Age'])\n",
    "    df['Age_category'] = df['Age_category'].transform(lambda x: round(x,-1)+10 if x > 1 else 1)\n",
    "\n",
    "    #df.insert(9,'Relatives', df['SibSp'] + df['Parch'] +1)\n",
    "\n",
    "    # Выделить признак количества пассажиров зарегистрированных по одному билету\n",
    "    df.insert(10,'Persons_per_ticket', df.groupby('Ticket')['Fare'].transform('count'))\n",
    "    # Заменить значения 0 на 1\n",
    "    df['Persons_per_ticket'] = df['Persons_per_ticket'].apply(lambda x: 1 if x == 0 else x)\n",
    "\n",
    "    # Выделить признак стоимости одного проездного места в билете\n",
    "    df.insert(11,'Price_per_person', (df['Fare'] / df['Persons_per_ticket']).round(decimals=2))\n",
    "    df['Price_per_person'] = df.groupby(['Pclass'])['Price_per_person'].transform(lambda x: x.fillna(x.median() if x.count()>0 else 0))\n",
    "\n",
    "    # Для признака \"Deck\" часть пропущенных значений заменить совпадающими по классу и стоимости места\n",
    "    df['Deck'] = df.groupby(['Pclass','Price_per_person'])['Deck'].transform(lambda x: x.fillna(x.mode()[0] if x.count()>0 else nan))\n",
    "    # Значения не соответсвующие ни одной из палуб корабля отнести к категории Unknown\n",
    "    df['Deck'] = df['Deck'].apply(lambda x: 'unknown' if x not in ['a','b','c','d','e','f','g'] else x)\n",
    "    # Оставшиеся пропущенные значения отнести к категории Unknown\n",
    "    df['Deck'].fillna('unknown', inplace=True)\n",
    "\n",
    "    # Для признака \"Embarked\" - заменить пропущенные значения наиболее частым значением данного признака\n",
    "    df['Embarked'].fillna(df.mode()['Embarked'][0], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(TRAIN_CSV_PATH, sep=',')\n",
    "\n",
    "# Привести все строковые значения к единому регистру, \n",
    "df_raw = df_raw.apply(lambda x: x.astype(str).str.lower() if x.dtype.name=='object' else x)\n",
    "# Удалить столбец 'PassengerId'\n",
    "df_raw.drop(['PassengerId'],axis=1, inplace=True)\n",
    "# Заменить значения \"nan\" на NULL/NAN для полей содрежащих строки\n",
    "df_raw.replace('nan', nan, inplace=True)\n",
    "# Заменить значения 0 на NULL/NAN для поля возраста стоимости билета\n",
    "df_raw['Age'].replace(0, nan, inplace=True)\n",
    "\n",
    "df_train = process_data(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исключаем из обучения поля 'Name','Ticket','Fare','Cabin'\n",
    "num_cols = ['Age','SibSp','Parch','Persons_per_ticket','Price_per_person']\n",
    "cat_cols = ['Survived','Pclass', 'Title', 'Sex', 'Age_category', 'Deck', 'Embarked']\n",
    "\n",
    "df_train[['Pclass', 'Age_category']] = df_train[['Pclass', 'Age_category']].astype('category')\n",
    "\n",
    "data = pd.concat((df_train[num_cols], pd.get_dummies(df_train[cat_cols])), axis=1)\n",
    "\n",
    "y_train = data['Survived']\n",
    "X_train = data.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_scores= []\n",
    "km_silhouette = []\n",
    "vmeasure_score =[]\n",
    "db_score = []\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score,v_measure_score\n",
    "#X_scaled=scaler.fit_transform(X_train)\n",
    "X_scaled=X_train\n",
    "for i in range(2,25):\n",
    "    km = KMeans(n_clusters=i, random_state=0).fit(X_scaled)\n",
    "    preds = km.predict(X_scaled)\n",
    "    \n",
    "    print(\"Score for number of cluster(s) {}: {}\".format(i,km.score(X_scaled)))\n",
    "    km_scores.append(-km.score(X_scaled))\n",
    "    \n",
    "    silhouette = silhouette_score(X_scaled,preds)\n",
    "    km_silhouette.append(silhouette)\n",
    "    print(\"Silhouette score for number of cluster(s) {}: {}\".format(i,silhouette))\n",
    "    \n",
    "    db = davies_bouldin_score(X_scaled,preds)\n",
    "    db_score.append(db)\n",
    "    print(\"Davies Bouldin score for number of cluster(s) {}: {}\".format(i,db))\n",
    "    \n",
    "    v_measure = v_measure_score(y_train,preds)\n",
    "    vmeasure_score.append(v_measure)\n",
    "    print(\"V-measure score for number of cluster(s) {}: {}\".format(i,v_measure))\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The elbow method for determining number of clusters\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,25)],y=km_scores,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"K-means score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,25)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=[i for i in range(2,25)],y=vmeasure_score,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"V-measure score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The silhouette coefficient method \\nfor determining number of clusters\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,25)],y=km_silhouette,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"Silhouette score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,25)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=[i for i in range(2,25)],y=db_score,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Davies-Bouldin score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(random_state=42,n_components=2)\n",
    "# используем метод fit_transform вместо fit, т.к. класс TSNE не использует метод transform\n",
    "X_tsne = tsne.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pp\n",
    "pp.scatter(X_tsne[:,0],X_tsne[:,1],c=y_train);\n",
    "plt.xlabel(\"t-SNE признак 0\")\n",
    "plt.xlabel(\"t-SNE признак 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_scores= []\n",
    "km_silhouette = []\n",
    "vmeasure_score =[]\n",
    "db_score = []\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score,v_measure_score\n",
    "#X_scaled=scaler.fit_transform(X_tsne)\n",
    "X_scaled=X_tsne\n",
    "for i in range(2,15):\n",
    "    km = KMeans(n_clusters=i, random_state=0).fit(X_scaled)\n",
    "    preds = km.predict(X_scaled)\n",
    "    \n",
    "    print(\"Score for number of cluster(s) {}: {}\".format(i,km.score(X_scaled)))\n",
    "    km_scores.append(-km.score(X_scaled))\n",
    "    \n",
    "    silhouette = silhouette_score(X_scaled,preds)\n",
    "    km_silhouette.append(silhouette)\n",
    "    print(\"Silhouette score for number of cluster(s) {}: {}\".format(i,silhouette))\n",
    "    \n",
    "    db = davies_bouldin_score(X_scaled,preds)\n",
    "    db_score.append(db)\n",
    "    print(\"Davies Bouldin score for number of cluster(s) {}: {}\".format(i,db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The elbow method for determining number of clusters\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,15)],y=km_scores,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"K-means score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,15)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=[i for i in range(2,15)],y=db_score,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Davies-Bouldin score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The silhouette coefficient method \\nfor determining number of clusters\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,15)],y=km_silhouette,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"Silhouette score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,15)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "# используем метод fit_transform вместо fit, т.к. класс TSNE не использует метод transform\n",
    "reducer.fit(X_train)\n",
    "X_umap = reducer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X_train.iloc[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['Age']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_umap_test = reducer.transform(np.array(test).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_umap_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pp\n",
    "pp.scatter(X_umap[:,0],X_umap[:,1],c=y_train);\n",
    "pp.scatter(X_umap_test[:,0],X_umap_test[:,1],s = 250, c='blue', marker='o');\n",
    "\n",
    "plt.xlabel(\"UMAP признак 0\")\n",
    "plt.xlabel(\"UMAP признак 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_scores= []\n",
    "km_silhouette = []\n",
    "vmeasure_score =[]\n",
    "db_score = []\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score,v_measure_score\n",
    "X_scaled=scaler.fit_transform(X_umap)\n",
    "for i in range(2,15):\n",
    "    km = KMeans(n_clusters=i, random_state=0).fit(X_scaled)\n",
    "    preds = km.predict(X_scaled)\n",
    "    \n",
    "    print(\"Score for number of cluster(s) {}: {}\".format(i,km.score(X_scaled)))\n",
    "    km_scores.append(-km.score(X_scaled))\n",
    "    \n",
    "    silhouette = silhouette_score(X_scaled,preds)\n",
    "    km_silhouette.append(silhouette)\n",
    "    print(\"Silhouette score for number of cluster(s) {}: {}\".format(i,silhouette))\n",
    "    \n",
    "    db = davies_bouldin_score(X_scaled,preds)\n",
    "    db_score.append(db)\n",
    "    print(\"Davies Bouldin score for number of cluster(s) {}: {}\".format(i,db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The elbow method for determining number of clusters\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,15)],y=km_scores,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"K-means score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,15)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The silhouette coefficient method \\nfor determining number of clusters\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,15)],y=km_silhouette,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"Silhouette score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,15)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=[i for i in range(2,15)],y=db_score,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Davies-Bouldin score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_train)\n",
    "X_scaled_tsne=scaler.fit_transform(X_tsne)\n",
    "km_tsne = KMeans(n_clusters=6, random_state=0).fit(X_scaled_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=6, random_state=0).fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "reducer.fit(X_train)\n",
    "X_umap = reducer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "km_tsne = KMeans(n_clusters=6, random_state=0).fit(X_scaled)\n",
    "assignments = km_tsne.labels_\n",
    "mglearn.discrete_scatter(X_scaled_tsne[:, 0], X_scaled_tsne[:, 1], assignments, ax=axes[0])\n",
    "\n",
    "km_umap = KMeans(n_clusters=6, random_state=0).fit(X_umap)\n",
    "assignments = km_umap.labels_\n",
    "mglearn.discrete_scatter(X_umap[:, 0], X_umap[:, 1], assignments, ax=axes[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redicer=[]\n",
    "for i in km_umap.cluster_centers_:\n",
    "    redicer.append(reducer.inverse_transform(i.reshape(1,-1))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(redicer), columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
